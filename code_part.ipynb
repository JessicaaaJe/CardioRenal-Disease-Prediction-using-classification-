{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF23a0PXzUjak26o0jSSub",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JessicaaaJe/CardioRenal-Disease-Prediction-using-classification-/blob/main/code_part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yl7clOh-Ige",
        "outputId": "e69c70fa-81af-495e-e751-52e81acb3dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART A**"
      ],
      "metadata": {
        "id": "9ssAf7j3sko0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "id": "8yKPlUjxDS3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/share_folders_csc373/Data/Assoc_Analysis_Vidhya.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "uVDonvdPDQR9",
        "outputId": "2159f64a-0562-4e29-a369-7b0fb26d18dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1   Bread    Wine  Eggs    Meat Cheese  Pencil  Diaper\n",
            "0  2   Bread  Cheese  Meat  Diaper   Wine    Milk  Pencil\n",
            "1  3  Cheese    Meat  Eggs    Milk   Wine     NaN     NaN\n",
            "2  4  Cheese    Meat  Eggs    Milk   Wine     NaN     NaN\n",
            "3  5    Meat  Pencil  Wine     NaN    NaN     NaN     NaN\n",
            "4  6    Eggs   Bread  Wine  Pencil   Milk  Diaper   Bagel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functions to implement the Apriori Algorithm**"
      ],
      "metadata": {
        "id": "-h5yw-hmoZ93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def candidate_generation(frequent_itemsets, k):\n",
        "    \"\"\"\n",
        "    Generate candidate k-itemsets using Fk-1 * Fk-1\n",
        "    Frequent itemsets is sorted in lexicographic order to avoid duplicates.\n",
        "    \"\"\"\n",
        "    candidate_itemsets = set()\n",
        "    sorted_frequent_itemsets = sorted(frequent_itemsets)\n",
        "\n",
        "    for i, itemset1 in enumerate(sorted_frequent_itemsets):\n",
        "        for itemset2 in sorted_frequent_itemsets[i + 1:]:\n",
        "            # Check if the first k-1 items are the same\n",
        "            if list(itemset1)[:k - 1] == list(itemset2)[:k - 1]:\n",
        "                # Combine if the first k-1 items are the same\n",
        "                combined = itemset1.union(itemset2)\n",
        "                candidate_itemsets.add(combined)\n",
        "    return candidate_itemsets"
      ],
      "metadata": {
        "id": "m73VDtc0obwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4998761-b02c-4c0b-8110-034b46105fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def candidate_prune(candidates, previous_frequent_itemsets, k):\n",
        "    pruned_candidates = set()\n",
        "    evious for candidate in candidates:\n",
        "        # fronzenset is set to make sure the list is hashable, for the later use of checking whether\n",
        "        # the subset had occured in the prfrequent itemsets.\n",
        "        # itertools.combinations generate all (k-1)-subsets for the candidate k-itemset\n",
        "        subsets = [frozenset(subset) for subset in itertools.combinations(candidate, k)]\n",
        "\n",
        "        # if all its (k-1)-subsets are in the set of frequent (k-1)-itemsets,\n",
        "        # otherwise eliminiate k itemsets that contain infrequent k-1 itemsets\n",
        "        if all(subset in previous_frequent_itemsets for subset in subsets):\n",
        "            pruned_candidates.add(candidate)\n",
        "    return pruned_candidates"
      ],
      "metadata": {
        "id": "vs7ZlMs7rZfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0467ef-91c1-4b67-eab5-2fd2b1c6a08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`hash tree is used to be more computational efficient`"
      ],
      "metadata": {
        "id": "4nwmC4FJ6YVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_support(transactions, candidates):\n",
        "    \"\"\"\n",
        "    Use a hash tree for efficient candidate storage and subset checking.\n",
        "    \"\"\"\n",
        "    count = {}\n",
        "    # Build a hash tree of candidates\n",
        "    hash_tree = build_hash_tree(candidates)\n",
        "\n",
        "    for transaction in transactions:\n",
        "        # Generate all subsets of the transaction that are of the same length as the candidates\n",
        "        transaction_subsets = generate_subsets(transaction, len(candidates[0]))\n",
        "\n",
        "        for subset in transaction_subsets:\n",
        "            if is_subset_in_hash_tree(subset, hash_tree):\n",
        "                candidate = frozenset(subset)  # Convert to frozenset to use as dictionary key\n",
        "                count[candidate] = count.get(candidate, 0) + 1\n",
        "\n",
        "    return count\n",
        "\n",
        "def is_subset_in_hash_tree(subset, hash_tree):\n",
        "    \"\"\"\n",
        "    Check if a subset is in the hash tree.\n",
        "    \"\"\"\n",
        "    node = hash_tree\n",
        "    for item in subset:\n",
        "        index = hash(item)\n",
        "        if index not in node['children']:\n",
        "            return False\n",
        "        node = node['children'][index]\n",
        "    return True\n",
        "\n",
        "def generate_subsets(transaction, subset_size):\n",
        "    \"\"\"\n",
        "    Generate all subsets of the transaction that are of the specified size.\n",
        "    \"\"\"\n",
        "    from itertools import combinations\n",
        "    return [set(s) for s in combinations(transaction, subset_size)]\n"
      ],
      "metadata": {
        "id": "7SF7hIYo7OS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8caedaea-a78e-45f0-811b-e19538d00aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def candidate_elimination(support_counts, transactions, minsup):\n",
        "    return [itemset for itemset, count in support_counts.items() if count / len(transactions) >= minsup]"
      ],
      "metadata": {
        "id": "NsfzPsvdn866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b644f9c-3b96-4ebc-dc0e-93c8cb8b91b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is a simple transaction dataset for test.**"
      ],
      "metadata": {
        "id": "aAQ3NizMNtJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = [\n",
        "    {'Bread', 'Milk'},\n",
        "    {'Bread', 'Diapers', 'Beer', 'Eggs'},\n",
        "    {'Milk', 'Diapers', 'Beer', 'Cola'},\n",
        "    {'Bread', 'Milk', 'Diapers', 'Beer'},\n",
        "    {'Bread', 'Milk', 'Diapers', 'Cola'}\n",
        "]"
      ],
      "metadata": {
        "id": "9ris-Jf282_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39892246-1110-4da3-8f72-593e6f79a13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minsup = 0.6\n",
        "print(f\"number of transactions:{len(transactions)}\")\n",
        "print(f\"minsup:{minsup}\\n\")\n",
        "all_frequent_itemsets = []\n",
        "\n",
        "# create initial candidate 1-itemsets\n",
        "unique_items = set(item for transaction in transactions for item in transaction)\n",
        "current_candidates = [frozenset([item]) for item in unique_items]\n",
        "\n",
        "\n",
        "k = 1\n",
        "while current_candidates:\n",
        "    counts = calculate_support(transactions, current_candidates)\n",
        "\n",
        "    # eliminate infrequent itemsets\n",
        "    frequent_itemsets = candidate_elimination(counts, transactions, minsup)\n",
        "    print(f\"Frequent {k}-itemsets: {[set(itemset) for itemset in frequent_itemsets]}\")\n",
        "\n",
        "    # If no frequent itemsets, break the loop\n",
        "    if not frequent_itemsets:\n",
        "        break\n",
        "\n",
        "    all_frequent_itemsets.extend(frequent_itemsets)\n",
        "\n",
        "    # Generate (k+1)-itemsets\n",
        "    next_candidates = candidate_generation(frequent_itemsets, k)\n",
        "    print(f\"\\nCandidate {k+1}-itemsets before pruning:{[set(itemset) for itemset in next_candidates]}\")\n",
        "\n",
        "    # Prune candidates that contain infrequent subsets\n",
        "    next_candidates = candidate_prune(next_candidates, set(frequent_itemsets), k)\n",
        "    print(f\"Candidate {k+1}-itemsets after pruning: {next_candidates}\")\n",
        "\n",
        "    # Set up for next iteration\n",
        "    current_candidates = next_candidates\n",
        "    k += 1\n",
        "\n",
        "print(\"\\nFinal Frequent Itemsets:\")\n",
        "for itemset in all_frequent_itemsets:\n",
        "    support_ratio = sum(1 for t in transactions if itemset.issubset(t)) / len(transactions)\n",
        "    print(f\"Itemset: {set(itemset)}, Support: {support_ratio:.3f}\")"
      ],
      "metadata": {
        "id": "83Fz0Ua_Dib4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d30025-27a8-495f-a023-cb23f1379a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of transactions:5\n",
            "minsup:0.6\n",
            "\n",
            "Frequent 1-itemsets: [{'Bread'}, {'Milk'}, {'Diapers'}, {'Beer'}]\n",
            "\n",
            "Candidate 2-itemsets before pruning:[{'Beer', 'Milk'}, {'Bread', 'Milk'}, {'Diapers', 'Beer'}, {'Bread', 'Diapers'}, {'Bread', 'Beer'}, {'Diapers', 'Milk'}]\n",
            "Candidate 2-itemsets after pruning: {frozenset({'Beer', 'Milk'}), frozenset({'Bread', 'Milk'}), frozenset({'Diapers', 'Beer'}), frozenset({'Bread', 'Diapers'}), frozenset({'Bread', 'Beer'}), frozenset({'Diapers', 'Milk'})}\n",
            "Frequent 2-itemsets: [{'Bread', 'Milk'}, {'Bread', 'Diapers'}, {'Diapers', 'Beer'}, {'Diapers', 'Milk'}]\n",
            "\n",
            "Candidate 3-itemsets before pruning:[{'Diapers', 'Beer', 'Milk'}, {'Bread', 'Diapers', 'Milk'}]\n",
            "Candidate 3-itemsets after pruning: {frozenset({'Bread', 'Diapers', 'Milk'})}\n",
            "Frequent 3-itemsets: []\n",
            "\n",
            "Final Frequent Itemsets:\n",
            "Itemset: {'Bread'}, Support: 0.800\n",
            "Itemset: {'Milk'}, Support: 0.800\n",
            "Itemset: {'Diapers'}, Support: 0.800\n",
            "Itemset: {'Beer'}, Support: 0.600\n",
            "Itemset: {'Bread', 'Milk'}, Support: 0.600\n",
            "Itemset: {'Bread', 'Diapers'}, Support: 0.600\n",
            "Itemset: {'Diapers', 'Beer'}, Support: 0.600\n",
            "Itemset: {'Diapers', 'Milk'}, Support: 0.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The algorithm has successfully beeen implemented. ***\n"
      ],
      "metadata": {
        "id": "04Kld5IEdxSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the DataFrame into a list of sets (transactions)\n",
        "transactions = df.apply(lambda row: set(row.dropna().values), axis=1).tolist()"
      ],
      "metadata": {
        "id": "mRjrKVEh991y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7b635b-0e7e-48d7-b1c5-bf15c30e1f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minsup = 0.2\n",
        "print(f\"number of transactions:{len(transactions)}\")\n",
        "print(f\"minsup:{minsup}\\n\")\n",
        "all_frequent_itemsets = []\n",
        "\n",
        "# create initial candidate 1-itemsets\n",
        "unique_items = set(item for transaction in transactions for item in transaction)\n",
        "current_candidates = [frozenset([item]) for item in unique_items]\n",
        "\n",
        "\n",
        "k = 1\n",
        "while current_candidates:\n",
        "    counts = calculate_support(transactions, current_candidates)\n",
        "\n",
        "    # eliminate infrequent itemsets\n",
        "    frequent_itemsets = candidate_elimination(counts, transactions, minsup)\n",
        "    print(f\"Frequent {k}-itemsets: {[set(itemset) for itemset in frequent_itemsets]}\")\n",
        "\n",
        "    # If no frequent itemsets, break the loop\n",
        "    if not frequent_itemsets:\n",
        "        break\n",
        "\n",
        "    all_frequent_itemsets.extend(frequent_itemsets)\n",
        "\n",
        "    # Generate (k+1)-itemsets\n",
        "    next_candidates = candidate_generation(frequent_itemsets, k)\n",
        "    print(f\"\\nCandidate {k+1}-itemsets before pruning:{[set(itemset) for itemset in next_candidates]}\")\n",
        "\n",
        "    # Prune candidates that contain infrequent subsets\n",
        "    next_candidates = candidate_prune(next_candidates, set(frequent_itemsets), k)\n",
        "    print(f\"Candidate {k+1}-itemsets after pruning: {next_candidates}\")\n",
        "\n",
        "    # Set up for next iteration\n",
        "    current_candidates = next_candidates\n",
        "    k += 1\n",
        "\n",
        "# output frequent itemsets in descending order of support ratio\n",
        "support_ratios = [(itemset, sum(1 for t in transactions if itemset.issubset(t)) / len(transactions)) for itemset in all_frequent_itemsets]\n",
        "sorted_frequent_itemsets = sorted(support_ratios, key=lambda x: x[1], reverse=True)\n",
        "print(\"\\nFinal Frequent Itemsets:\")\n",
        "for index, (itemset, support_ratio) in enumerate(sorted_frequent_itemsets,start =1):\n",
        "    print(f\"{index}. Itemset: {set(itemset)}, Support: {support_ratio:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsMui6g4-CQF",
        "outputId": "f2485836-50ee-4451-b6e7-ada9652ac978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of transactions:314\n",
            "minsup:0.2\n",
            "\n",
            "Frequent 1-itemsets: [{'Wine'}, {'Meat'}, {'Milk'}, {'Pencil'}, {'Cheese'}, {'Diaper'}, {'Bread'}, {'Eggs'}, {'Bagel'}]\n",
            "\n",
            "Candidate 2-itemsets before pruning:[{'Wine', 'Diaper'}, {'Bagel', 'Cheese'}, {'Cheese', 'Meat'}, {'Pencil', 'Cheese'}, {'Pencil', 'Eggs'}, {'Cheese', 'Diaper'}, {'Wine', 'Meat'}, {'Bread', 'Meat'}, {'Bagel', 'Diaper'}, {'Meat', 'Eggs'}, {'Bagel', 'Milk'}, {'Wine', 'Milk'}, {'Pencil', 'Meat'}, {'Bread', 'Diaper'}, {'Meat', 'Diaper'}, {'Wine', 'Cheese'}, {'Cheese', 'Milk'}, {'Eggs', 'Milk'}, {'Bagel', 'Meat'}, {'Bread', 'Bagel'}, {'Pencil', 'Diaper'}, {'Bread', 'Cheese'}, {'Eggs', 'Diaper'}, {'Pencil', 'Bagel'}, {'Meat', 'Milk'}, {'Bagel', 'Eggs'}, {'Bread', 'Milk'}, {'Pencil', 'Milk'}, {'Wine', 'Bread'}, {'Cheese', 'Eggs'}, {'Diaper', 'Milk'}, {'Wine', 'Bagel'}, {'Wine', 'Eggs'}, {'Bread', 'Eggs'}, {'Wine', 'Pencil'}, {'Pencil', 'Bread'}]\n",
            "Candidate 2-itemsets after pruning: {frozenset({'Wine', 'Diaper'}), frozenset({'Bagel', 'Cheese'}), frozenset({'Cheese', 'Meat'}), frozenset({'Pencil', 'Cheese'}), frozenset({'Pencil', 'Eggs'}), frozenset({'Cheese', 'Diaper'}), frozenset({'Wine', 'Meat'}), frozenset({'Bread', 'Meat'}), frozenset({'Bagel', 'Diaper'}), frozenset({'Meat', 'Eggs'}), frozenset({'Bagel', 'Milk'}), frozenset({'Wine', 'Milk'}), frozenset({'Pencil', 'Meat'}), frozenset({'Bread', 'Diaper'}), frozenset({'Meat', 'Diaper'}), frozenset({'Wine', 'Cheese'}), frozenset({'Cheese', 'Milk'}), frozenset({'Eggs', 'Milk'}), frozenset({'Bagel', 'Meat'}), frozenset({'Bread', 'Bagel'}), frozenset({'Pencil', 'Diaper'}), frozenset({'Bread', 'Cheese'}), frozenset({'Eggs', 'Diaper'}), frozenset({'Pencil', 'Bagel'}), frozenset({'Meat', 'Milk'}), frozenset({'Bagel', 'Eggs'}), frozenset({'Bread', 'Milk'}), frozenset({'Pencil', 'Milk'}), frozenset({'Wine', 'Bread'}), frozenset({'Cheese', 'Eggs'}), frozenset({'Diaper', 'Milk'}), frozenset({'Wine', 'Bagel'}), frozenset({'Wine', 'Eggs'}), frozenset({'Bread', 'Eggs'}), frozenset({'Wine', 'Pencil'}), frozenset({'Pencil', 'Bread'})}\n",
            "Frequent 2-itemsets: [{'Wine', 'Meat'}, {'Wine', 'Milk'}, {'Wine', 'Cheese'}, {'Wine', 'Diaper'}, {'Meat', 'Milk'}, {'Cheese', 'Meat'}, {'Bread', 'Meat'}, {'Cheese', 'Milk'}, {'Bread', 'Milk'}, {'Bread', 'Cheese'}, {'Bread', 'Diaper'}, {'Meat', 'Eggs'}, {'Eggs', 'Milk'}, {'Cheese', 'Eggs'}, {'Wine', 'Eggs'}, {'Bagel', 'Milk'}, {'Bread', 'Bagel'}]\n",
            "\n",
            "Candidate 3-itemsets before pruning:[{'Wine', 'Cheese', 'Eggs'}, {'Wine', 'Meat', 'Diaper'}, {'Bread', 'Meat', 'Milk'}, {'Wine', 'Diaper', 'Milk'}, {'Wine', 'Cheese', 'Diaper'}, {'Meat', 'Eggs', 'Milk'}, {'Bread', 'Meat', 'Diaper'}, {'Wine', 'Meat', 'Eggs'}, {'Bread', 'Bagel', 'Meat'}, {'Cheese', 'Meat', 'Milk'}, {'Bread', 'Cheese', 'Milk'}, {'Cheese', 'Meat', 'Eggs'}, {'Wine', 'Meat', 'Milk'}, {'Bread', 'Bagel', 'Milk'}, {'Bread', 'Bagel', 'Diaper'}, {'Wine', 'Cheese', 'Meat'}, {'Wine', 'Eggs', 'Diaper'}, {'Cheese', 'Eggs', 'Milk'}, {'Bread', 'Bagel', 'Cheese'}, {'Bread', 'Cheese', 'Diaper'}, {'Wine', 'Eggs', 'Milk'}, {'Wine', 'Cheese', 'Milk'}, {'Bread', 'Cheese', 'Meat'}, {'Bread', 'Diaper', 'Milk'}]\n",
            "Candidate 3-itemsets after pruning: {frozenset({'Wine', 'Cheese', 'Eggs'}), frozenset({'Wine', 'Cheese', 'Meat'}), frozenset({'Cheese', 'Meat', 'Milk'}), frozenset({'Cheese', 'Eggs', 'Milk'}), frozenset({'Bread', 'Cheese', 'Milk'}), frozenset({'Meat', 'Eggs', 'Milk'}), frozenset({'Bread', 'Meat', 'Milk'}), frozenset({'Cheese', 'Meat', 'Eggs'}), frozenset({'Wine', 'Meat', 'Milk'}), frozenset({'Wine', 'Eggs', 'Milk'}), frozenset({'Wine', 'Cheese', 'Milk'}), frozenset({'Bread', 'Bagel', 'Milk'}), frozenset({'Bread', 'Cheese', 'Meat'}), frozenset({'Wine', 'Meat', 'Eggs'})}\n",
            "Frequent 3-itemsets: [{'Cheese', 'Meat', 'Milk'}, {'Cheese', 'Meat', 'Eggs'}]\n",
            "\n",
            "Candidate 4-itemsets before pruning:[{'Cheese', 'Meat', 'Eggs', 'Milk'}]\n",
            "Candidate 4-itemsets after pruning: set()\n",
            "\n",
            "Final Frequent Itemsets:\n",
            "1. Itemset: {'Milk'}, Support: 0.503\n",
            "2. Itemset: {'Bread'}, Support: 0.503\n",
            "3. Itemset: {'Cheese'}, Support: 0.500\n",
            "4. Itemset: {'Meat'}, Support: 0.475\n",
            "5. Itemset: {'Wine'}, Support: 0.436\n",
            "6. Itemset: {'Eggs'}, Support: 0.436\n",
            "7. Itemset: {'Bagel'}, Support: 0.427\n",
            "8. Itemset: {'Diaper'}, Support: 0.404\n",
            "9. Itemset: {'Pencil'}, Support: 0.360\n",
            "10. Itemset: {'Cheese', 'Meat'}, Support: 0.322\n",
            "11. Itemset: {'Cheese', 'Milk'}, Support: 0.306\n",
            "12. Itemset: {'Cheese', 'Eggs'}, Support: 0.296\n",
            "13. Itemset: {'Bread', 'Milk'}, Support: 0.280\n",
            "14. Itemset: {'Bread', 'Bagel'}, Support: 0.280\n",
            "15. Itemset: {'Wine', 'Cheese'}, Support: 0.268\n",
            "16. Itemset: {'Meat', 'Eggs'}, Support: 0.264\n",
            "17. Itemset: {'Wine', 'Meat'}, Support: 0.248\n",
            "18. Itemset: {'Meat', 'Milk'}, Support: 0.245\n",
            "19. Itemset: {'Eggs', 'Milk'}, Support: 0.245\n",
            "20. Itemset: {'Wine', 'Eggs'}, Support: 0.239\n",
            "21. Itemset: {'Bread', 'Cheese'}, Support: 0.236\n",
            "22. Itemset: {'Wine', 'Diaper'}, Support: 0.232\n",
            "23. Itemset: {'Bread', 'Diaper'}, Support: 0.229\n",
            "24. Itemset: {'Bagel', 'Milk'}, Support: 0.226\n",
            "25. Itemset: {'Wine', 'Milk'}, Support: 0.220\n",
            "26. Itemset: {'Cheese', 'Meat', 'Eggs'}, Support: 0.213\n",
            "27. Itemset: {'Bread', 'Meat'}, Support: 0.204\n",
            "28. Itemset: {'Cheese', 'Meat', 'Milk'}, Support: 0.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART B**"
      ],
      "metadata": {
        "id": "1GjagWuMt_Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "from mlxtend.frequent_patterns import association_rules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAeH03b1y3Hq",
        "outputId": "50409385-5ca3-4e3f-c0a0-00221033b669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  all items are converted to strings to ensure consistency in fitting FP Tree\n",
        "transactions_list = df.apply(lambda row: row.dropna().astype(str).tolist(), axis=1).tolist()"
      ],
      "metadata": {
        "id": "f-Tdr9UfCZ8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5587cba3-00b3-4557-e296-683fa93744ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the transaction into a binary matrix\n",
        "# where each row represents a transaction and each column represents a unique item\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions_list).transform(transactions_list)\n",
        "ohe_df = pd.DataFrame(te_ary, columns=te.columns_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4xCEJ5Ct-a-",
        "outputId": "991b56e6-e3be-440b-b2ce-00782b211a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_support = 0.2\n",
        "frequent_itemsets_fp = fpgrowth(ohe_df, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Sort the frequent itemsets by support in descending order\n",
        "sorted_frequent_itemsets_fp = frequent_itemsets_fp.sort_values(by='support', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Sorted frequent itemsets from FP-Growth:\")\n",
        "for index, row in sorted_frequent_itemsets_fp.iterrows():\n",
        "    print(f\"{index}. Itemset: {sorted(list(row['itemsets']))}, Support: {row['support']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdQGsXbLufbY",
        "outputId": "dbcb2f28-efef-46f3-a939-9336e3517754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted frequent itemsets from FP-Growth:\n",
            "0. Itemset: ['Milk'], Support: 0.503\n",
            "1. Itemset: ['Bread'], Support: 0.503\n",
            "2. Itemset: ['Cheese'], Support: 0.500\n",
            "3. Itemset: ['Meat'], Support: 0.475\n",
            "4. Itemset: ['Wine'], Support: 0.436\n",
            "5. Itemset: ['Eggs'], Support: 0.436\n",
            "6. Itemset: ['Bagel'], Support: 0.427\n",
            "7. Itemset: ['Diaper'], Support: 0.404\n",
            "8. Itemset: ['Pencil'], Support: 0.360\n",
            "9. Itemset: ['Cheese', 'Meat'], Support: 0.322\n",
            "10. Itemset: ['Cheese', 'Milk'], Support: 0.306\n",
            "11. Itemset: ['Cheese', 'Eggs'], Support: 0.296\n",
            "12. Itemset: ['Bread', 'Milk'], Support: 0.280\n",
            "13. Itemset: ['Bagel', 'Bread'], Support: 0.280\n",
            "14. Itemset: ['Cheese', 'Wine'], Support: 0.268\n",
            "15. Itemset: ['Eggs', 'Meat'], Support: 0.264\n",
            "16. Itemset: ['Meat', 'Wine'], Support: 0.248\n",
            "17. Itemset: ['Eggs', 'Milk'], Support: 0.245\n",
            "18. Itemset: ['Meat', 'Milk'], Support: 0.245\n",
            "19. Itemset: ['Bread', 'Wine'], Support: 0.242\n",
            "20. Itemset: ['Eggs', 'Wine'], Support: 0.239\n",
            "21. Itemset: ['Bread', 'Cheese'], Support: 0.236\n",
            "22. Itemset: ['Diaper', 'Wine'], Support: 0.232\n",
            "23. Itemset: ['Bread', 'Diaper'], Support: 0.229\n",
            "24. Itemset: ['Bagel', 'Milk'], Support: 0.226\n",
            "25. Itemset: ['Milk', 'Wine'], Support: 0.220\n",
            "26. Itemset: ['Cheese', 'Eggs', 'Meat'], Support: 0.213\n",
            "27. Itemset: ['Cheese', 'Meat', 'Milk'], Support: 0.204\n",
            "28. Itemset: ['Bread', 'Meat'], Support: 0.204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The frequent patterns generated from Apriori algorithm and FP Tree are the same. There are in total 28 frequent patterns generated given the minimum support = 0.2. ***"
      ],
      "metadata": {
        "id": "VyrWQgM80b0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART C**"
      ],
      "metadata": {
        "id": "dl3P_Edx-uRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interesting rules will be disucssed in the report."
      ],
      "metadata": {
        "id": "in-F0LyX-ys-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rules = association_rules(sorted_frequent_itemsets_fp, metric=\"confidence\", min_threshold=0.2)\n",
        "\n",
        "# Convert frozensets to sorted lists for display\n",
        "rules['antecedents'] = rules['antecedents'].apply(lambda a: sorted(list(a)))\n",
        "rules['consequents'] = rules['consequents'].apply(lambda c: sorted(list(c)))\n",
        "\n",
        "print(\"Association Rules:\")\n",
        "for index, rule in rules.iterrows():\n",
        "    print(f\"Rule {index + 1}: {rule['antecedents']} => {rule['consequents']}, \"\n",
        "          f\"Confidence: {rule['confidence']:.3f}, \"\n",
        "          f\"Support: {rule['support']:.3f}, \"\n",
        "          f\"Lift: {rule['lift']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IvyX5nbvWyU",
        "outputId": "f0ddc1eb-3361-45b2-d2e6-1a47fa65e23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Association Rules:\n",
            "Rule 1: ['Cheese'] => ['Meat'], Confidence: 0.643, Support: 0.322, Lift: 1.356\n",
            "Rule 2: ['Meat'] => ['Cheese'], Confidence: 0.678, Support: 0.322, Lift: 1.356\n",
            "Rule 3: ['Cheese'] => ['Milk'], Confidence: 0.611, Support: 0.306, Lift: 1.215\n",
            "Rule 4: ['Milk'] => ['Cheese'], Confidence: 0.608, Support: 0.306, Lift: 1.215\n",
            "Rule 5: ['Cheese'] => ['Eggs'], Confidence: 0.592, Support: 0.296, Lift: 1.358\n",
            "Rule 6: ['Eggs'] => ['Cheese'], Confidence: 0.679, Support: 0.296, Lift: 1.358\n",
            "Rule 7: ['Bread'] => ['Milk'], Confidence: 0.557, Support: 0.280, Lift: 1.107\n",
            "Rule 8: ['Milk'] => ['Bread'], Confidence: 0.557, Support: 0.280, Lift: 1.107\n",
            "Rule 9: ['Bread'] => ['Bagel'], Confidence: 0.557, Support: 0.280, Lift: 1.305\n",
            "Rule 10: ['Bagel'] => ['Bread'], Confidence: 0.657, Support: 0.280, Lift: 1.305\n",
            "Rule 11: ['Wine'] => ['Cheese'], Confidence: 0.613, Support: 0.268, Lift: 1.226\n",
            "Rule 12: ['Cheese'] => ['Wine'], Confidence: 0.535, Support: 0.268, Lift: 1.226\n",
            "Rule 13: ['Meat'] => ['Eggs'], Confidence: 0.557, Support: 0.264, Lift: 1.277\n",
            "Rule 14: ['Eggs'] => ['Meat'], Confidence: 0.606, Support: 0.264, Lift: 1.277\n",
            "Rule 15: ['Wine'] => ['Meat'], Confidence: 0.569, Support: 0.248, Lift: 1.200\n",
            "Rule 16: ['Meat'] => ['Wine'], Confidence: 0.523, Support: 0.248, Lift: 1.200\n",
            "Rule 17: ['Eggs'] => ['Milk'], Confidence: 0.562, Support: 0.245, Lift: 1.117\n",
            "Rule 18: ['Milk'] => ['Eggs'], Confidence: 0.487, Support: 0.245, Lift: 1.117\n",
            "Rule 19: ['Meat'] => ['Milk'], Confidence: 0.517, Support: 0.245, Lift: 1.027\n",
            "Rule 20: ['Milk'] => ['Meat'], Confidence: 0.487, Support: 0.245, Lift: 1.027\n",
            "Rule 21: ['Wine'] => ['Bread'], Confidence: 0.555, Support: 0.242, Lift: 1.102\n",
            "Rule 22: ['Bread'] => ['Wine'], Confidence: 0.481, Support: 0.242, Lift: 1.102\n",
            "Rule 23: ['Wine'] => ['Eggs'], Confidence: 0.547, Support: 0.239, Lift: 1.255\n",
            "Rule 24: ['Eggs'] => ['Wine'], Confidence: 0.547, Support: 0.239, Lift: 1.255\n",
            "Rule 25: ['Bread'] => ['Cheese'], Confidence: 0.468, Support: 0.236, Lift: 0.937\n",
            "Rule 26: ['Cheese'] => ['Bread'], Confidence: 0.471, Support: 0.236, Lift: 0.937\n",
            "Rule 27: ['Wine'] => ['Diaper'], Confidence: 0.533, Support: 0.232, Lift: 1.317\n",
            "Rule 28: ['Diaper'] => ['Wine'], Confidence: 0.575, Support: 0.232, Lift: 1.317\n",
            "Rule 29: ['Bread'] => ['Diaper'], Confidence: 0.456, Support: 0.229, Lift: 1.127\n",
            "Rule 30: ['Diaper'] => ['Bread'], Confidence: 0.567, Support: 0.229, Lift: 1.127\n",
            "Rule 31: ['Bagel'] => ['Milk'], Confidence: 0.530, Support: 0.226, Lift: 1.053\n",
            "Rule 32: ['Milk'] => ['Bagel'], Confidence: 0.449, Support: 0.226, Lift: 1.053\n",
            "Rule 33: ['Wine'] => ['Milk'], Confidence: 0.504, Support: 0.220, Lift: 1.001\n",
            "Rule 34: ['Milk'] => ['Wine'], Confidence: 0.437, Support: 0.220, Lift: 1.001\n",
            "Rule 35: ['Cheese', 'Meat'] => ['Eggs'], Confidence: 0.663, Support: 0.213, Lift: 1.520\n",
            "Rule 36: ['Cheese', 'Eggs'] => ['Meat'], Confidence: 0.720, Support: 0.213, Lift: 1.518\n",
            "Rule 37: ['Eggs', 'Meat'] => ['Cheese'], Confidence: 0.807, Support: 0.213, Lift: 1.614\n",
            "Rule 38: ['Cheese'] => ['Eggs', 'Meat'], Confidence: 0.427, Support: 0.213, Lift: 1.614\n",
            "Rule 39: ['Meat'] => ['Cheese', 'Eggs'], Confidence: 0.450, Support: 0.213, Lift: 1.518\n",
            "Rule 40: ['Eggs'] => ['Cheese', 'Meat'], Confidence: 0.489, Support: 0.213, Lift: 1.520\n",
            "Rule 41: ['Cheese', 'Meat'] => ['Milk'], Confidence: 0.634, Support: 0.204, Lift: 1.259\n",
            "Rule 42: ['Cheese', 'Milk'] => ['Meat'], Confidence: 0.667, Support: 0.204, Lift: 1.405\n",
            "Rule 43: ['Meat', 'Milk'] => ['Cheese'], Confidence: 0.831, Support: 0.204, Lift: 1.662\n",
            "Rule 44: ['Cheese'] => ['Meat', 'Milk'], Confidence: 0.408, Support: 0.204, Lift: 1.662\n",
            "Rule 45: ['Meat'] => ['Cheese', 'Milk'], Confidence: 0.430, Support: 0.204, Lift: 1.405\n",
            "Rule 46: ['Milk'] => ['Cheese', 'Meat'], Confidence: 0.405, Support: 0.204, Lift: 1.259\n",
            "Rule 47: ['Bread'] => ['Meat'], Confidence: 0.405, Support: 0.204, Lift: 0.854\n",
            "Rule 48: ['Meat'] => ['Bread'], Confidence: 0.430, Support: 0.204, Lift: 0.854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}